# Auto-generated by Lumenary
from __future__ import annotations 
import os
import enum
from enum import Enum
import typing
from typing import Optional, Tuple, Dict, overload, Literal, Union, get_args, Type
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from inspect import isclass
import uuid

import requests
import aiocache
from supabase import create_client, Client
from supabase.lib.client_options import ClientOptions
import instructor
from openai import OpenAI
from openai.types import ChatModel as OpenAIModel
from anthropic import Anthropic
from anthropic.types import Model as AnthropicModel

load_dotenv()

class MediaService:
    def __init__(self, supabase_client, cache_ttl: int = 300):
        self.client = supabase_client
        self.cache_ttl = cache_ttl
        self.cache = aiocache.Cache()

    async def get_bytes(self, media_ref: MediaReference) -> bytes:
        cache_key = f"media_bytes:{media_ref.bucket}:{media_ref.path}"

        # Try cache first
        cached = await self.cache.get(cache_key)
        if cached:
            return cached

        # If not in cache, download and store
        try:
            data = await self.client.storage.from_(media_ref.bucket).download(
                media_ref.path
            )
            await self.cache.set(cache_key, data, ttl=self.cache_ttl)
            return data
        except Exception as e:
            # Log error and maybe return a default image?
            raise MediaFetchError(f"Failed to fetch media: {str(e)}")

    async def get_metadata(self, media_ref: MediaReference) -> Dict:
        try:
            return await self.client.storage.from_(media_ref.bucket).get_metadata(
                media_ref.path
            )
        except Exception as e:
            raise MediaMetadataError(f"Failed to fetch metadata: {str(e)}")

class MediaReference(BaseModel):
    pass

class MediaFetchError(Exception):
    def __init__(self, message):
        self.message = message
        super().__init__(self.message)

class MediaMetadataError(Exception):
    def __init__(self, message):
        self.message = message
        super().__init__(self.message)

#####

class Router:
    def post_data(endpoint, data):
        """POST to an endpoint on Lumenary's back-end service router"""
        base = os.getenv("ROUTER_BASE_URL")
        port = os.getenv("ROUTER_PORT")
        base_url = f"{base}:{port}"
        response = requests.post(
            f'{base_url}/{endpoint}',
            headers={"Content-Type": "application/json"},
            json=data
        )
        if not response.ok:
            return None
        return response.json()

class ModelProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"

openai_client = None
if os.getenv("OPENAI_API_KEY") is not None:
    openai_client = instructor.from_openai(OpenAI())

anthropic_client = None
if os.getenv("ANTHROPIC_API_KEY") is not None:
    anthropic_client = instructor.from_anthropic(Anthropic())

provider_info_mapping: Dict[ModelProvider, ...] = {
    ModelProvider.OPENAI: {
        "allowed_models": get_args(OpenAIModel),
        "client": openai_client,
    },
    ModelProvider.ANTHROPIC: {
        "allowed_models": get_args(get_args(AnthropicModel)[1]),
        "client": anthropic_client,
    },
}

class Persisted(BaseModel):
    __abstract__ = True

    @classmethod
    def _is_valid_postgres_name(cls, table_name: str) -> Tuple[bool, str]:
        """Validates if a string is a valid PostgreSQL table name.
        """
        RESERVED_KEYWORDS = {
            'all', 'analyse', 'analyze', 'and', 'any', 'array', 'as', 'asc',
            'asymmetric', 'authorization', 'between', 'binary', 'both', 'case',
            'cast', 'check', 'collate', 'column', 'constraint', 'create',
            'cross', 'current_date', 'current_role', 'current_time',
            'current_timestamp', 'current_user', 'default', 'deferrable',
            'desc', 'distinct', 'do', 'else', 'end', 'except', 'false', 'for',
            'foreign', 'freeze', 'from', 'full', 'grant', 'group', 'having',
            'ilike', 'in', 'initially', 'inner', 'intersect', 'into', 'is',
            'isnull', 'join', 'leading', 'left', 'like', 'limit', 'localtime',
            'localtimestamp', 'natural', 'not', 'notnull', 'null', 'offset',
            'on', 'only', 'or', 'order', 'outer', 'overlaps', 'placing',
            'primary', 'references', 'right', 'select', 'session_user',
            'similar', 'some', 'symmetric', 'table', 'then', 'to', 'trailing',
            'true', 'union', 'unique', 'user', 'using', 'verbose', 'when',
            'where'
        }

        if len(table_name.encode('utf-8')) > 63:
            return False, "Table names must be less than 63 characters."

        if not table_name[0].isalpha() and table_name[0] != '_':
            return False, "Table names must begin with letters or underscores"

        if not all(c.isalnum() or c == '_' for c in table_name):
            return False, "Table names must only contain letters, numbers, or underscores"

        if table_name.lower() in RESERVED_KEYWORDS:
            return False, "Table names cannot be reserved keywords"

        if table_name.lower() != table_name:
            return False, "Table names should be all lowercase"

        return True, "Good"

    @classmethod
    def _resolve_type_to_column(cls, type_name, annotation, **kwargs):
        """
        """
        null_statement = ""
        if not kwargs.get("optional_parent", False) or kwargs.get("is_primary", False):
            null_statement = "NOT NULL"
        if isclass(annotation) and issubclass(annotation, Enum):
            # This should be more robust, but it is only possible to use for our media mapping table atm
            return type_name.split(".")[1].lower()
        match type_name:
            case "builtins.str":
                statement = f"VARCHAR {null_statement}"
            case "builtins.int":
                statement = f"INTEGER {null_statement}"
            case "builtins.float":
                statement = f"FLOAT {null_statement}"
            case "builtins.bool":
                statement = f"BOOLEAN {null_statement}"
            case "datetime.datetime":
                statement = f"TIMESTAMP WITHOUT TIME ZONE {null_statement}"
            case "datetime.date":
                statement = f"DATE {null_statement}"
            case "datetime.time":
                statement = f"TIME WITHOUT TIME ZONE {null_statement}"
            case "datetime.timedelta":
                statement = f"INTERVAL {null_statement}"
            case "typing.Optional":
                child_type = get_args(annotation)[0]
                child_type_name = f"{child_type.__module__}.{child_type.__name__}"
                statement = cls._resolve_type_to_column(child_type_name,
                                                        child_type,
                                                        optional_parent=True)
            case "uuid.UUID":
                statement = f"UUID {null_statement}"
            case _:
                raise ValueError(
                    f"Could not convert type {annotation} to SQL type (type not supported)"
                )
        return statement.strip()

    @classmethod
    def _get_sql_table_name(cls, schema_name=None):
        if not hasattr(cls, "__tablename__"):
            tablename = cls.__name__.lower()
        else:
            tablename = cls.__tablename__
        tablename_is_valid, validity_reason = cls._is_valid_postgres_name(tablename)
        if not tablename_is_valid:
            raise ValueError(validity_reason)
        if schema_name is None:
          return tablename
        return f"{schema_name}.{tablename}"

    @classmethod
    def generate_sql_schema(cls, schema_name):
        """Generate a Postgres-compatible create table command from a Persisted model
        """
        sql_statement_prototype = {
            "tablename": None,
            "column_statements": [],
            "primary_key_name": None,
        }
        sql_statement_prototype["tablename"] = cls._get_sql_table_name(schema_name)

        # Fill column statement and primary key name
        for field_name, field_info in cls.model_fields.items():
            field_name_is_valid, validity_reason = cls._is_valid_postgres_name(
                field_name)
            if not field_name_is_valid:
                raise ValueError(validity_reason)
            annotation = field_info.annotation
            if annotation is None:
                raise ValueError(f"Field {field_name} has no type annotation")
            if (type(annotation) not in [type, typing._UnionGenericAlias, enum.EnumMeta]):
                raise ValueError(
                    f"Could not convert type {annotation} to SQL type (annotation not a type)"
                )
            type_name = f"{annotation.__module__}.{annotation.__name__}"
            is_primary = field_info.json_schema_extra.get(
                'primary_key',
                False) if field_info.json_schema_extra else False
            if is_primary:
                if sql_statement_prototype["primary_key_name"] is not None:
                    raise ValueError("You may only specify one primary key")
                sql_statement_prototype["primary_key_name"] = field_name

            column_type = cls._resolve_type_to_column(type_name,
                                                      annotation,
                                                      is_primary=is_primary)
            sql_statement_prototype["column_statements"].append(
                f"{field_name} {column_type}")

        if len(sql_statement_prototype["column_statements"]) == 0:
            raise ValueError(
                "Please specify at least one column for your table")

        # Create table statement
        statement = f"CREATE TABLE IF NOT EXISTS {sql_statement_prototype['tablename']} (\n"
        statement += ",\n".join([
            f"    {column}"
            for column in sql_statement_prototype["column_statements"]
        ])
        if sql_statement_prototype["primary_key_name"] is not None:
            statement += f",\n    PRIMARY KEY ({sql_statement_prototype['primary_key_name']})\n"
        statement += ")"
        return statement


class Lumenary:
    def get_supa_client() -> Client:
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")
        schema = os.getenv("SUPABASE_SCHEMA")
        opts = ClientOptions(schema=schema, persist_session=False)
        print(url, key, schema)
        print(opts)
        client: Client = create_client(url, key, options=opts)
        return client

    def _direct_query(
        provider: ModelProvider,
        model: Union[OpenAIModel, AnthropicModel],
        system_prompt: str,
        prompt: str,
        response_model: BaseModel = None
    ):
        provider_enum = ModelProvider(provider)
        relevant_client = provider_info_mapping[provider_enum]["client"]
        chat_completion_response = relevant_client.chat.completions.create(
            model="gpt-4o-mini",
            response_model=response_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt},
            ],
        )
        return chat_completion_response.choices[0].message.content

    @overload
    def llm(
        provider: Literal[ModelProvider.ANTHROPIC],
        model: AnthropicModel,
        system_prompt: str,
        prompt: str,
        response_model: BaseModel = None
    ) -> str: ...

    @overload
    def llm(
        provider: Literal[ModelProvider.OPENAI],
        model: OpenAIModel,
        system_prompt: str,
        prompt: str,
        response_model: BaseModel = None
    ) -> str: ...

    def llm(
        provider: ModelProvider,
        model: Union[OpenAIModel, AnthropicModel],
        system_prompt: str,
        prompt: str,
        response_model: Type[BaseModel] = None,
        *args,
        **kwargs,
    ) -> str:
        named_args = locals()
        del named_args["args"]
        del named_args["kwargs"]

        provider_enum = ModelProvider(provider)
        assert model in provider_info_mapping[provider_enum]["allowed_models"], f"This is not a valid model for {provider}"
        relevant_client = provider_info_mapping[provider_enum]["client"]
        if relevant_client is None:
            if response_model is None:
                response_model_to_send = {
                    "name": None,
                    "schema": None,
                }
            else:
                response_model_to_send = {
                    "name": response_model.__name__,
                    "schema": response_model.model_json_schema(),
                }
            payload = {
                "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
                "model": model,
                "responseModel": response_model_to_send,
                "options": {"stream": False}
            }
            response = Router.post_data("model/structured", payload)
            if response is None:
                return None
            if (provider_enum == ModelProvider.ANTHROPIC):
                message_str = response["content"][0]["text"]
                return message_str
            message_str = response["choices"][0]["message"]["content"]
            return message_str
        else:
            return Lumenary._direct_query(*args, **{**named_args, **kwargs})
